#!rnn.py

# external parameters set explicitely by sisyphus
ext_model = config.value("ext_model", None)
ext_learning_rate_file = config.value("ext_learning_rate_file", None)

# external parameters set by parameter dictionary
# training
ext_num_epochs = config.int("ext_num_epochs", 0)

# data
ext_partition_epoch = config.int("ext_partition_epoch", 20)
ext_training_zips = eval(config.value("ext_training_zips", None))
ext_dev_zips = eval(config.value("ext_dev_zips", None))

ext_norm_mean_value = float(config.value("ext_norm_mean_value", None))
ext_norm_std_dev_value = float(config.value("ext_norm_std_dev_value", None))
ext_char_vocab = config.value("ext_char_epoch", None)


EpochSplit = 1
accum_grad_multiple_step = 2
adam = True
batch_size = 7000
batching = 'random'
cleanup_old_models = True
debug_add_check_numerics_on_output = False
debug_mode = False


def get_dataset(key):
  dataset = {'audio': { 'feature_options': {'fmin': 60},
                        'features': 'db_mel_filterbank',
                        'join_frames': 3,
                        'norm_mean': ext_norm_mean_value,
                        'norm_std_dev': ext_norm_std_dev_value,
                        'num_feature_filters': 80,
                        'peak_normalization': False,
                        'preemphasis': 0.97,
                        'step_len': 0.0125,
                        'window_len': 0.05},
             'class': 'OggZipDataset',
             'partition_epoch': 1,
             'targets': { 'class': 'CharacterTargets',
                          'unknown_label': None,
                          'vocab_file': ext_char_vocab}
            }
  if key == "train":
    dataset['path'] = ext_training_zips
    dataset['seq_ordering'] = 'laplace:.1000'
  elif key == "dev":
    dataset['path'] = ext_dev_zips
    dataset['seq_ordering'] = 'sorted_reverse'
  else:
    assert False, "invalid dataset key"
  return dataset

dev = get_dataset('dev')
train = get_dataset('train')

device = 'gpu'
extern_data = {'classes': (53, 1), 'data': (240, 2)}
gradient_clip = 1
gradient_noise = 0.0
learning_rate = 0.001
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 5
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = 'learning_rates'
learning_rates = [0.001]
log = ['./crnn.log']
log_batch_size = True
log_verbosity = 5
max_seq_length = {'data': 430}
max_seqs = 200
model = '/u/rossenbach/experiments/switchboard_test/work/crnn/training/CRNNTrainingJob.jvLVQcGdQA8L/output/models/epoch'
multiprocessing = True
network = { 'decoder': { 'cheating': False,
               'class': 'rec',
               'from': [],
               'max_seq_len': 1200,
               'target': 'data',
               'unit': { 'accum_att_weights': { 'class': 'eval',
                                                'eval': 'source(0) + source(1)',
                                                'from': ['prev:accum_att_weights', 'att_weights'],
                                                'is_output_layer': True,
                                                'out_type': {'dim': 1, 'shape': (None, 1)}},
                         'att0': {'base': 'base:encoder', 'class': 'generic_attention', 'weights': 'att_weights'},
                         'att_energy': {'activation': None, 'class': 'linear', 'from': ['att_energy_tanh'], 'n_out': 1, 'with_bias': False},
                         'att_energy_in': { 'class': 'combine',
                                            'from': ['base:enc_ctx', 's_transformed', 'location_feedback_transformed'],
                                            'kind': 'add',
                                            'n_out': 128},
                         'att_energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': ['att_energy_in']},
                         'att_weights': {'class': 'softmax_over_spatial', 'from': ['att_energy']},
                         'choice': {'beam_size': 1, 'class': 'choice', 'from': ['output'], 'input_type': 'regression', 'target': 'data'},
                         'convolved_att': { 'L2': 1e-07,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (31,),
                                            'from': ['feedback_pad_right'],
                                            'n_out': 32,
                                            'padding': 'valid'},
                         'decoder_1': { 'class': 'rnn_cell',
                                        'from': ['pre_net_layer_2_out', 'prev:att0'],
                                        'n_out': 768,
                                        'unit': 'zoneoutlstm',
                                        'unit_opts': {'zoneout_factor_cell': 0.1, 'zoneout_factor_output': 0.1}},
                         'decoder_2': { 'class': 'rnn_cell',
                                        'from': ['decoder_1'],
                                        'n_out': 768,
                                        'unit': 'zoneoutlstm',
                                        'unit_opts': {'zoneout_factor_cell': 0.1, 'zoneout_factor_output': 0.1}},
                         'end': {'class': 'compare', 'from': ['stop_token_sigmoid'], 'kind': 'greater', 'value': 0.5},
                         'entropy': { 'class': 'eval',
                                      'eval': '-tf.reduce_sum(source(0)*safe_log(source(0)), axis=-1, keepdims=True)',
                                      'from': ['att_weights'],
                                      'loss': 'as_is',
                                      'loss_scale': 0.0001},
                         'feedback_pad_left': { 'axes': 1,
                                                'class': 'pad',
                                                'from': ['prev:accum_att_weights'],
                                                'mode': 'constant',
                                                'out_type': {'dim': 1, 'shape': (None, 1)},
                                                'padding': ((15, 0),),
                                                'value': 1},
                         'feedback_pad_right': { 'axes': 1,
                                                 'class': 'pad',
                                                 'from': ['feedback_pad_left'],
                                                 'mode': 'constant',
                                                 'out_type': {'dim': 1, 'shape': (None, 1)},
                                                 'padding': ((0, 15),),
                                                 'value': 0},
                         'location_feedback_transformed': { 'L2': 1e-07,
                                                            'activation': None,
                                                            'class': 'linear',
                                                            'dropout': 0.1,
                                                            'from': ['convolved_att'],
                                                            'n_out': 128,
                                                            'with_bias': False},
                         'output': { 'activation': None,
                                     'class': 'linear',
                                     'from': ['decoder_2', 'att0'],
                                     'loss': 'mean_l1',
                                     'loss_scale': 1.0,
                                     'n_out': 240,
                                     'target': 'data'},
                         'pre_net_layer_1': {'L2': 1e-07, 'activation': 'relu', 'class': 'linear', 'from': ['pre_slice'], 'n_out': 128},
                         'pre_net_layer_2': { 'L2': 1e-07,
                                              'activation': 'relu',
                                              'class': 'linear',
                                              'dropout': 0.5,
                                              'dropout_noise_shape': (None, None, None),
                                              'dropout_on_forward': True,
                                              'from': ['pre_net_layer_1'],
                                              'n_out': 64},
                         'pre_net_layer_2_out': { 'class': 'dropout',
                                                  'dropout': 0.5,
                                                  'dropout_noise_shape': (None, None, None),
                                                  'dropout_on_forward': True,
                                                  'from': ['pre_net_layer_2']},
                         'pre_slice': {'axis': 'F', 'class': 'slice', 'from': ['prev:choice'], 'slice_start': 160},
                         's_transformed': { 'L2': 1e-07,
                                            'activation': None,
                                            'class': 'linear',
                                            'dropout': 0.5,
                                            'from': ['decoder_2'],
                                            'n_out': 128,
                                            'with_bias': False},
                         'stop_token': { 'activation': None,
                                         'class': 'linear',
                                         'from': ['decoder_2', 'att0'],
                                         'loss': 'bin_ce',
                                         'loss_scale': 1.0,
                                         'n_out': 1,
                                         'target': 'stop_token_target'},
                         'stop_token_sigmoid': {'activation': 'sigmoid', 'class': 'activation', 'from': ['stop_token']}}},
  'embed_batchnorm_cv_0': {'class': 'batch_norm', 'from': ['embed_conv0']},
  'embed_batchnorm_cv_1': {'class': 'batch_norm', 'from': ['embed_conv1']},
  'embed_batchnorm_cv_2': {'class': 'batch_norm', 'from': ['embed_conv2']},
  'embed_conv0': {'L2': 1e-07, 'activation': 'relu', 'class': 'conv', 'filter_size': (5,), 'from': ['embedding'], 'n_out': 128, 'padding': 'same'},
  'embed_conv0_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['embed_batchnorm_cv_0']},
  'embed_conv1': { 'L2': 1e-07,
                   'activation': 'relu',
                   'class': 'conv',
                   'filter_size': (5,),
                   'from': ['embed_conv0_out'],
                   'n_out': 128,
                   'padding': 'same'},
  'embed_conv1_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['embed_batchnorm_cv_1']},
  'embed_conv2': { 'L2': 1e-07,
                   'activation': 'relu',
                   'class': 'conv',
                   'filter_size': (5,),
                   'from': ['embed_conv1_out'],
                   'n_out': 128,
                   'padding': 'same'},
  'embed_conv2_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['embed_batchnorm_cv_2']},
  'embedding': {'activation': None, 'class': 'linear', 'from': ['data:classes'], 'n_out': 128},
  'enc_ctx': { 'L2': 1e-07,
               'activation': None,
               'class': 'linear',
               'dropout': 0.5,
               'from': ['encoder', 'encoder_position'],
               'n_out': 128,
               'with_bias': True},
  'encoder': {'class': 'copy', 'dropout': 0.0, 'from': ['lstm0_fw', 'lstm0_bw', 'style_att']},
  'encoder_position': {'class': 'positional_encoding', 'from': ['lstm0_fw'], 'n_out': 64, 'out_type': {'dim': 64, 'shape': (None, 64)}},
  'lstm0_bw': { 'class': 'rec',
                'direction': -1,
                'from': ['embed_conv2_out'],
                'n_out': 256,
                'unit': 'zoneoutlstm',
                'unit_opts': {'zoneout_factor_cell': 0.1, 'zoneout_factor_output': 0.1}},
  'lstm0_fw': { 'class': 'rec',
                'direction': 1,
                'from': ['embed_conv2_out'],
                'n_out': 256,
                'unit': 'zoneoutlstm',
                'unit_opts': {'zoneout_factor_cell': 0.1, 'zoneout_factor_output': 0.1}},
  'mse_output': {'class': 'copy', 'from': ['output'], 'loss': 'mse', 'loss_scale': 0.0, 'n_out': 240, 'target': 'data'},
  'output': { 'class': 'combine',
              'from': ['decoder', 'post_conv_tf'],
              'kind': 'add',
              'loss': 'mean_l1',
              'loss_scale': 0.25,
              'n_out': 240,
              'target': 'data'},
  'post_batchnorm_cv_0': {'class': 'batch_norm', 'from': ['post_conv0']},
  'post_batchnorm_cv_1': {'class': 'batch_norm', 'from': ['post_conv1']},
  'post_batchnorm_cv_2': {'class': 'batch_norm', 'from': ['post_conv2']},
  'post_batchnorm_cv_3': {'class': 'batch_norm', 'from': ['post_conv3']},
  'post_batchnorm_cv_4': {'class': 'batch_norm', 'from': ['post_conv4']},
  'post_conv0': {'L2': 1e-07, 'activation': 'relu', 'class': 'conv', 'filter_size': (5,), 'from': ['decoder'], 'n_out': 256, 'padding': 'same'},
  'post_conv0_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['post_batchnorm_cv_0']},
  'post_conv1': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv0_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv1_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['post_batchnorm_cv_1']},
  'post_conv2': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv1_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv2_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['post_batchnorm_cv_2']},
  'post_conv3': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv2_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv3_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['post_batchnorm_cv_3']},
  'post_conv4': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv3_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv4_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': (None, None, None), 'from': ['post_batchnorm_cv_4']},
  'post_conv_tf': {'activation': None, 'class': 'conv', 'filter_size': (5,), 'from': ['post_conv4_out'], 'n_out': 240, 'padding': 'same'},
  'pre_slice': {'axis': 'F', 'class': 'slice', 'from': ['data'], 'slice_start': 160},
  'ref_enc': {'class': 'rec', 'direction': 1, 'from': ['reshape_enc'], 'n_out': 128, 'unit': 'nativelstm'},
  'ref_reduce': {'class': 'get_last_hidden_state', 'combine': 'concat', 'from': ['ref_enc'], 'n_out': 128},
  'ref_trans': {'activation': None, 'class': 'linear', 'dropout': 0.2, 'from': ['ref_reduce'], 'n_out': 128},
  'reshape_enc': {'axes': ['F', 's:-1'], 'class': 'merge_dims', 'from': ['style_conv_layer_6_bn'], 'n_out': 256},
  'style_att': {'base': 'style_tokens', 'class': 'generic_attention', 'weights': 'style_weights'},
  'style_conv_layer_1': { 'activation': 'relu',
                          'class': 'conv',
                          'filter_size': (3, 3),
                          'from': ['pre_slice'],
                          'input_add_feature_dim': True,
                          'n_out': 32,
                          'padding': 'same',
                          'strides': (2, 2)},
  'style_conv_layer_1_bn': {'class': 'batch_norm', 'from': ['style_conv_layer_1']},
  'style_conv_layer_2': { 'activation': 'relu',
                          'class': 'conv',
                          'dropout': 0.2,
                          'filter_size': (3, 3),
                          'from': ['style_conv_layer_1_bn'],
                          'n_out': 32,
                          'padding': 'same',
                          'strides': (2, 2)},
  'style_conv_layer_2_bn': {'class': 'batch_norm', 'from': ['style_conv_layer_2']},
  'style_conv_layer_3': { 'activation': 'relu',
                          'class': 'conv',
                          'dropout': 0.2,
                          'filter_size': (3, 3),
                          'from': ['style_conv_layer_2_bn'],
                          'n_out': 64,
                          'padding': 'same',
                          'strides': (2, 2)},
  'style_conv_layer_3_bn': {'class': 'batch_norm', 'from': ['style_conv_layer_3']},
  'style_conv_layer_4': { 'activation': 'relu',
                          'class': 'conv',
                          'dropout': 0.2,
                          'filter_size': (3, 3),
                          'from': ['style_conv_layer_3_bn'],
                          'n_out': 64,
                          'padding': 'same',
                          'strides': (2, 2)},
  'style_conv_layer_4_bn': {'class': 'batch_norm', 'from': ['style_conv_layer_4']},
  'style_conv_layer_5': { 'activation': 'relu',
                          'class': 'conv',
                          'dropout': 0.2,
                          'filter_size': (3, 3),
                          'from': ['style_conv_layer_4_bn'],
                          'n_out': 128,
                          'padding': 'same',
                          'strides': (2, 2)},
  'style_conv_layer_5_bn': {'class': 'batch_norm', 'from': ['style_conv_layer_5']},
  'style_conv_layer_6': { 'activation': 'relu',
                          'class': 'conv',
                          'dropout': 0.2,
                          'filter_size': (3, 3),
                          'from': ['style_conv_layer_5_bn'],
                          'n_out': 128,
                          'padding': 'same',
                          'strides': (2, 2)},
  'style_conv_layer_6_bn': {'class': 'batch_norm', 'from': ['style_conv_layer_6']},
  'style_energy': { 'activation': None,
                    'class': 'linear',
                    'from': ['style_tanh'],
                    'n_out': 1,
                    'out_type': {'dim': 1, 'shape': (100, 1), 'time_dim_axis': 1},
                    'with_bias': False},
  'style_energy_in': { 'class': 'combine',
                       'from': ['style_trans', 'ref_trans'],
                       'kind': 'add',
                       'n_out': 128,
                       'out_type': {'dim': 128, 'shape': (100, 128), 'time_dim_axis': 1}},
  'style_entropy': {'class': 'eval', 'eval': '-source(0)*safe_log(source(0))', 'from': ['style_weights'], 'loss': 'as_is', 'loss_scale': 0.0},
  'style_tanh': {'activation': 'tanh', 'class': 'activation', 'dropout': 0.1, 'from': ['style_energy_in']},
  'style_tokens': { 'class': 'variable',
                    'init': 'glorot_normal',
                    'out_type': {'dim': 128, 'shape': (100, 128), 'time_dim_axis': 1},
                    'shape': (100, 128),
                    'time_axis': 1},
  'style_trans': {'activation': None, 'class': 'linear', 'from': ['style_tokens'], 'n_out': 128},
  'style_weights': {'class': 'softmax_over_spatial', 'from': ['style_energy']},
  'stop_token_target': {'class': 'eval',
                        'eval': "self.network.get_config().typed_value('_stop_token_target')(source(0, as_data=True))",
                        'from': ['data'],
                        'register_as_extern_data': 'stop_token_target',
                        'out_type': {'shape': (None, 1), 'dim': 1}}
            }
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 3
newbob_multi_update_interval = 1
newbob_relative_error_threshold = 0
num_epochs = 200
num_inputs = 240
optimizer_epsilon = 1e-08
save_interval = 1
stop_on_nonfinite_train_score = False
target = 'data'
task = 'train'
tf_log_memory_usage = True

truncation = -1
update_on_device = True
use_learning_rate_control_always = True
use_tensorflow = True


def custom_construction_algo(idx, net_dict):
    if idx == 5:
      return None
      
    postnet_loss_scale = max(min((idx/5*0.25), 0.25), 0.01)
    stop_token_loss_scale = min(idx/5, 1.0) 
    net_dict['output']['loss_scale'] = postnet_loss_scale
    net_dict['decoder']['unit']['stop_token']['loss_scale'] = stop_token_loss_scale 
        
    return net_dict

pretrain = {"repetitions": 5, "construction_algo": custom_construction_algo}

def _stop_token_target(data):
  import tensorflow as tf
  time_axis = data.get_dynamic_axes()[0]
  stop_position = tf.expand_dims(data.get_dynamic_size(time_axis), axis=1) - 6

  ramp = tf.expand_dims(tf.range(tf.shape(data.placeholder)[1]), axis=0)
  full_ramp = tf.tile(ramp, [tf.shape(data.placeholder)[0], 1])
  adapted_ramp = tf.minimum(tf.maximum(full_ramp - stop_position, 0), 5)

  return tf.cast(tf.expand_dims(adapted_ramp, 2), dtype="float32") / 5

