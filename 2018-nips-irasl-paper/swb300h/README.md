The attention baseline is `base.config`
which gets `{"Hub5'00:": {'Σ': 19.1, 'CH': 25.3, 'SWB': 12.8}, "Hub5'01:": {'Σ': 19.0}}` in epoch 80.
The overall best attention model is `base.6l.red6.pretrain-start4l-red6-below-grow3.config`
which gets `{"Hub5'00:": {'Σ': 17.8, 'CH': 23.7, 'SWB': 11.9}, "Hub5'01:": {'Σ': 17.7}}` in epoch 72.

`dropout*.config` are hybrid HMM/LSTM configs.
