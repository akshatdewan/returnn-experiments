#!crnn/rnn.py
# kate: syntax python;
# -*- mode: python -*-
# sublime: syntax 'Packages/Python Improved/PythonImproved.tmLanguage'
# vim:set expandtab tabstop=4 fenc=utf-8 ff=unix ft=python:

# Example config for shallow fusion using a Transformer LM.

import os
import numpy
from subprocess import check_output, CalledProcessError
from Pretrain import WrapEpochValue

# task
my_dir = os.path.dirname(os.path.abspath(__file__))  # .../config-train/
my_base_dir = os.path.normpath(my_dir + "/../base")  # base
use_tensorflow = True
task = "train"
device = "gpu"
multiprocessing = True
update_on_device = True

debug_mode = False
if int(os.environ.get("RETURNN_DEBUG", "0")):
    print("** DEBUG MODE")
    debug_mode = True

if config.has("beam_size"):
    beam_size = config.int("beam_size", 0)
    print("** beam_size %i" % beam_size)
else:
    beam_size = 12

# data
num_inputs = 40
num_outputs = {"classes": (10025, 1), "data": (num_inputs, 2)}  # see vocab
EpochSplit = 20


def get_dataset(key, subset=None, train_partition_epoch=None):
    d = {
        'class': 'LibriSpeechCorpus',
        'path': 'base/dataset/ogg-zips',
        "use_zip": True,
        "use_ogg": True,
        "use_cache_manager": not debug_mode,
        "prefix": key,
        "bpe": {
            'bpe_file': 'base/dataset/trans.bpe.codes',
            'vocab_file': 'base/dataset/trans.bpe.vocab',
            'seq_postfix': [0],
            'unknown_label': '<unk>'},
        "audio": {
            "norm_mean": "base/dataset/stats.mean.txt",
            "norm_std_dev": "base/dataset/stats.std_dev.txt"},
    }
    if key.startswith("train"):
        d["partition_epoch"] = train_partition_epoch
        if key == "train":
            d["epoch_wise_filter"] = {
                (1, 5): {
                    'max_mean_len': 75,  # chars, should be around 14 bpe labels
                    'subdirs': ['train-clean-100', 'train-clean-360']}}
        #d["audio"]["random_permute"] = True
        num_seqs = 281241  # total
        d["seq_ordering"] = "laplace:%i" % (num_seqs // 1000)
    else:
        d["fixed_random_seed"] = 1
        d["seq_ordering"] = "sorted_reverse"
    if subset:
        d["fixed_random_subset"] = subset  # faster
    return d


train = get_dataset("train", train_partition_epoch=EpochSplit)
dev = get_dataset("dev", subset=3000)
cache_size = "0"
window = 1

# shallow fusion params:

if config.has("lm_scale"):
    lm_scale = config.float("lm_scale", 0.)
    print("** lm_scale %.f" % lm_scale)
else:
    lm_scale = 0.36

# LSTM LM params:

def fusion_eval4(am_score, lm_score):
    """
    Penalize EOS emission.
    - Relative threshold
    - Compare to max logP over vocab\{eos}

    Similar to: 3.1.2 in https://arxiv.org/abs/1904.02619

    :param tf.Tensor am_score: (batch,vocab) in +log space
    :param tf.Tensor lm_score: (batch,vocab) in +log space
    """
    import tensorflow as tf
    gamma = 1.1
    combo_score = am_score + lm_scale * lm_score
    idxs = tf.expand_dims(tf.range(tf.shape(lm_score)[-1], dtype=tf.int32), 0)  # (1, vocab)
    idxs += tf.zeros_like(lm_score, dtype=tf.int32)  # (batch, vocab)
    neg_infs = -float("inf") + tf.zeros_like(lm_score, dtype=tf.float32)
    max_val = tf.expand_dims(tf.reduce_max(tf.where(tf.equal(idxs,0), neg_infs, combo_score), axis=1), 1)
    thr_vals = max_val * gamma + tf.zeros_like(lm_score, dtype=tf.float32)
    dummy_score = tf.where(tf.greater_equal(combo_score, thr_vals), combo_score, neg_infs)
    final_score = tf.where(tf.equal(idxs,0), dummy_score, combo_score)
    return final_score

fusion_eval_str = "self.network.get_config().typed_value('fusion_eval4')(safe_log(source(0)), safe_log(source(1)))"

# Transformer params.
num_layers = 24
ff_dim = 2048
num_heads = 8
emb_dim = 128
qk_dim = 512
v_dim = qk_dim
trans_out_dim = 512
dropout = 0.0

# Universal.
tied_params = False

# Output layer.
bottleneck_dim = 0
output_sampling_loss = False
output_num_sampled = 16384
output_use_full_softmax = False
place_output_param_on_cpu = False

# Input embedding.
place_emb_on_cpu = True  # E.g. for adagrad.

# Initializer.
forward_weights_initializer = "variance_scaling_initializer(mode='fan_in', distribution='uniform', scale=1.0)"


# network
# (also defined by num_inputs & num_outputs)
target = "classes"
EncKeyTotalDim = 1024
AttNumHeads = 1
EncKeyPerHeadDim = EncKeyTotalDim // AttNumHeads
EncValueTotalDim = 2048
EncValuePerHeadDim = EncValueTotalDim // AttNumHeads
LstmDim = EncValueTotalDim // 2

network = {
"source": {"class": "eval", "eval": "tf.clip_by_value(source(0), -3.0, 3.0)"},

"lstm0_fw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": 1, "from": ["source"] },
"lstm0_bw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": -1, "from": ["source"] },
"lstm0_pool": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (3,), "from": ["lstm0_fw", "lstm0_bw"], "trainable": False},

"lstm1_fw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": 1, "from": ["lstm0_pool"], "dropout": 0.3 },
"lstm1_bw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": -1, "from": ["lstm0_pool"], "dropout": 0.3 },
"lstm1_pool": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (2,), "from": ["lstm1_fw", "lstm1_bw"], "trainable": False},

"lstm2_fw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": 1, "from": ["lstm1_pool"], "dropout": 0.3 },
"lstm2_bw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": -1, "from": ["lstm1_pool"], "dropout": 0.3 },
"lstm2_pool": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (1,), "from": ["lstm2_fw", "lstm2_bw"], "trainable": False},

"lstm3_fw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": 1, "from": ["lstm2_pool"], "dropout": 0.3 },
"lstm3_bw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": -1, "from": ["lstm2_pool"], "dropout": 0.3 },
"lstm3_pool": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (1,), "from": ["lstm3_fw", "lstm3_bw"], "trainable": False},

"lstm4_fw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": 1, "from": ["lstm3_pool"], "dropout": 0.3 },
"lstm4_bw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": -1, "from": ["lstm3_pool"], "dropout": 0.3 },
"lstm4_pool": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (1,), "from": ["lstm4_fw", "lstm4_bw"], "trainable": False},

"lstm5_fw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": 1, "from": ["lstm4_pool"], "dropout": 0.3 },
"lstm5_bw" : { "class": "rec", "unit": "nativelstm2", "n_out" : LstmDim, "direction": -1, "from": ["lstm4_pool"], "dropout": 0.3 },

"encoder": {"class": "copy", "from": ["lstm5_fw", "lstm5_bw"]},  # dim: EncValueTotalDim
"enc_ctx": {"class": "linear", "activation": None, "with_bias": True, "from": ["encoder"], "n_out": EncKeyTotalDim},  # preprocessed_attended in Blocks
"inv_fertility": {"class": "linear", "activation": "sigmoid", "with_bias": False, "from": ["encoder"], "n_out": AttNumHeads},
"enc_value": {"class": "split_dims", "axis": "F", "dims": (AttNumHeads, EncValuePerHeadDim), "from": ["encoder"]},  # (B, enc-T, H, D'/H)

"output": {"class": "rec", "from": [], 'cheating': config.bool("cheating", False), "unit": {
   "output": {"class": "choice", "target": target, "beam_size": beam_size, "cheating": config.bool("cheating", False),
              "from": ["combo_output_log_prob"], "initial_output": 0, "input_type": "log_prob"},
   "combo_output_log_prob": {"class": "eval", "from": ["output_prob", "lm_output" ], "eval": fusion_eval_str},

   'lm_target_embed_raw': { 'activation': None,
                                  "param_device": "CPU" if place_emb_on_cpu else None,
                                  'class': 'linear',
                                  'forward_weights_init': forward_weights_initializer,
                                  'from': ["prev:output"],
                                  'n_out': emb_dim,
                                  'with_bias': False},
            'lm_target_embed_with_pos': {'add_to_input': True, 'class': 'positional_encoding', 'from': ['lm_target_embed_raw']},
            'lm_target_embed': {'class': 'dropout', 'dropout': dropout, 'from': ['lm_target_embed_with_pos']},
            'lm_target_embed_lin': { 'activation': None,
                                   'class': 'linear',
                                   'forward_weights_init': forward_weights_initializer,
                                   'from': ['lm_target_embed'],
                                   'n_out': trans_out_dim,
                                   'with_bias': False},
            'lm_dec_0': {'class': 'copy', 'from': ['lm_dec_0_ff_out']},
            'lm_dec_0_self_att_laynorm': {'class': 'layer_norm', 'from': ['lm_target_embed_lin']},
            'lm_dec_0_self_att_att': { 'attention_dropout': dropout,
                                     'attention_left_only': True,
                                     'class': 'self_attention',
                                     'forward_weights_init': forward_weights_initializer,
                                     'from': ['lm_dec_0_self_att_laynorm'],
                                     'n_out': v_dim,
                                     'num_heads': num_heads,
                                     'total_key_dim': qk_dim},
            'lm_dec_0_self_att_lin': { 'activation': None,
                                     'class': 'linear',
                                     'forward_weights_init': forward_weights_initializer,
                                     'from': ['lm_dec_0_self_att_att'],
                                     'n_out': trans_out_dim,
                                     'with_bias': False},
            'lm_dec_0_self_att_drop': {'class': 'dropout', 'dropout': dropout, 'from': ['lm_dec_0_self_att_lin']},
            'lm_dec_0_att_out': { 'class': 'combine',
                                'from': ['lm_target_embed_lin', 'lm_dec_0_self_att_drop'],
                                'kind': 'add',
                                'n_out': trans_out_dim,
                                'trainable': True},
            'lm_dec_0_ff_laynorm': {'class': 'layer_norm', 'from': ['lm_dec_0_att_out']},
            'lm_dec_0_ff_conv1': { 'activation': 'relu',
                                 'class': 'linear',
                                 'forward_weights_init': forward_weights_initializer,
                                 'from': ['lm_dec_0_ff_laynorm'],
                                 'n_out': ff_dim,
                                 'with_bias': True},
            'lm_dec_0_ff_conv2': { 'activation': None,
                                 'class': 'linear',
                                 'dropout': dropout,
                                 'forward_weights_init': forward_weights_initializer,
                                 'from': ['lm_dec_0_ff_conv1'],
                                 'n_out': trans_out_dim,
                                 'with_bias': True},
            'lm_dec_0_ff_drop': {'class': 'dropout', 'dropout': dropout, 'from': ['lm_dec_0_ff_conv2']},
            'lm_dec_0_ff_out': {'class': 'combine', 'from': ['lm_dec_0_att_out', 'lm_dec_0_ff_drop'], 'kind': 'add', 'n_out': trans_out_dim},

    "end": {"class": "compare", "from": ["output"], "value": 0},
    'target_embed': {'class': 'linear', 'activation': None, "with_bias": False, 'from': ['output'], "n_out": 621, "initial_output": 0},  # feedback_input
    "weight_feedback": {"class": "linear", "activation": None, "with_bias": False, "from": ["prev:accum_att_weights"], "n_out": EncKeyTotalDim},
    "s_transformed": {"class": "linear", "activation": None, "with_bias": False, "from": ["s"], "n_out": EncKeyTotalDim},
    "energy_in": {"class": "combine", "kind": "add", "from": ["base:enc_ctx", "weight_feedback", "s_transformed"], "n_out": EncKeyTotalDim},
    "energy_tanh": {"class": "activation", "activation": "tanh", "from": ["energy_in"]},
    "energy": {"class": "linear", "activation": None, "with_bias": False, "from": ["energy_tanh"], "n_out": AttNumHeads},  # (B, enc-T, H)
    "att_weights": {"class": "softmax_over_spatial", "from": ["energy"]},  # (B, enc-T, H)
    "accum_att_weights": {"class": "eval", "from": ["prev:accum_att_weights", "att_weights", "base:inv_fertility"],
        "eval": "source(0) + source(1) * source(2) * 0.5", "out_type": {"dim": AttNumHeads, "shape": (None, AttNumHeads)}},
    "att0": {"class": "generic_attention", "weights": "att_weights", "base": "base:enc_value"},  # (B, H, V)
    "att": {"class": "merge_dims", "axes": "except_batch", "from": ["att0"]},  # (B, H*V)
    "s": {"class": "rnn_cell", "unit": "LSTMBlock", "from": ["prev:target_embed", "prev:att"], "n_out": 1000},  # transform
    "readout_in": {"class": "linear", "from": ["s", "prev:target_embed", "att"], "activation": None, "n_out": 1000},  # merge + post_merge bias
    "readout": {"class": "reduce_out", "mode": "max", "num_pieces": 2, "from": ["readout_in"]},
    "output_prob": {
        "class": "softmax", "from": ["readout"], "dropout": 0.3,
        "target": target, "loss": "ce", "loss_opts": {"label_smoothing": 0.1}}
}, "target": target, "max_seq_len": "max_len_from('base:encoder')"},

"decision": {
    "class": "decide", "from": ["output"], "loss": "edit_distance", "target": target,
    "loss_opts": {
        #"debug_print": True
        }
    },

"ctc": {"class": "softmax", "from": ["encoder"], "loss": "ctc", "target": target,
    "loss_opts": {"beam_width": 1, "ctc_opts": {"ignore_longer_outputs_than_inputs": True}}}
}
search_output_layer = "decision"
debug_print_layer_output_template = True


def add_layer(cur_lay_id, prev_lay_id):
  network['output']['unit']['lm_dec_%(cur_lay_id)s' % {'cur_lay_id': cur_lay_id} ] = {
    'class': 'copy', 'from': ['lm_dec_%(cur_lay_id)s_ff_out' % {'cur_lay_id': cur_lay_id} ]}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_self_att_laynorm' % {'cur_lay_id': cur_lay_id} ] = {
    'class': 'layer_norm', 'from': ['lm_dec_%(prev_lay_id)s' % {'prev_lay_id': prev_lay_id}]}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_self_att_att' % {'cur_lay_id': cur_lay_id} ] = {
    'attention_dropout': dropout,
    'attention_left_only': True,
    'reuse_params': 'lm_dec_0_self_att_att' if tied_params else None,
    'class': 'self_attention',
    'forward_weights_init': forward_weights_initializer,
    'from': ['lm_dec_%(cur_lay_id)s_self_att_laynorm' % {'cur_lay_id': cur_lay_id}],
    'n_out': v_dim,
    'num_heads': num_heads,
    'total_key_dim': qk_dim}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_self_att_lin' % {'cur_lay_id': cur_lay_id} ] = {
    'activation': None,
    'class': 'linear',
    'reuse_params': 'lm_dec_0_self_att_lin' if tied_params else None,
    'forward_weights_init': forward_weights_initializer,
    'from': ['lm_dec_%(cur_lay_id)s_self_att_att' % {'cur_lay_id': cur_lay_id}],
    'n_out': trans_out_dim,
    'with_bias': False}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_self_att_drop' % {'cur_lay_id': cur_lay_id} ] = {
    'class': 'dropout', 'dropout': dropout, 'from': ['lm_dec_%(cur_lay_id)s_self_att_lin' % {'cur_lay_id': cur_lay_id}]}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_att_out' % {'cur_lay_id': cur_lay_id} ] = {
    'class': 'combine',
    'from': ['lm_dec_%(prev_lay_id)s' % {'prev_lay_id': prev_lay_id}, 'lm_dec_%(cur_lay_id)s_self_att_drop' % {'cur_lay_id': cur_lay_id}],
    'kind': 'add',
    'n_out': trans_out_dim,
    'trainable': True}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_ff_laynorm' % {'cur_lay_id': cur_lay_id}] = {
    'class': 'layer_norm', 'from': ['lm_dec_%(cur_lay_id)s_att_out' % {'cur_lay_id': cur_lay_id}]}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_ff_conv1' % {'cur_lay_id': cur_lay_id}] = {
                       'class': 'linear',
                       'activation': 'relu',
                       'forward_weights_init': forward_weights_initializer,
                       'reuse_params': 'lm_dec_0_ff_conv1' if tied_params else None,
                       'from': ['lm_dec_%(cur_lay_id)s_ff_laynorm' % {'cur_lay_id': cur_lay_id}],
                       'n_out': ff_dim,
                       'with_bias': True}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_ff_conv2' % {'cur_lay_id': cur_lay_id} ] = {
                       'class': 'linear',
                       'activation': None,
                       'dropout': dropout,
                       'reuse_params': 'lm_dec_0_ff_conv2' if tied_params else None,
                       'forward_weights_init': forward_weights_initializer,
                       'from': ['lm_dec_%(cur_lay_id)s_ff_conv1' % {'cur_lay_id': cur_lay_id}],
                       'n_out': trans_out_dim,
                       'with_bias': True}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_ff_drop' % {'cur_lay_id': cur_lay_id}] = {
    'class': 'dropout', 'dropout': dropout, 'from': ['lm_dec_%(cur_lay_id)s_ff_conv2' % {'cur_lay_id': cur_lay_id}]}
  network['output']['unit']['lm_dec_%(cur_lay_id)s_ff_out' % {'cur_lay_id': cur_lay_id}] = {
    'class': 'combine', 'from': ['lm_dec_%(cur_lay_id)s_att_out' % {'cur_lay_id': cur_lay_id}, 'lm_dec_%(cur_lay_id)s_ff_drop' % {'cur_lay_id': cur_lay_id}],
    'kind': 'add', 'n_out': trans_out_dim}

# Stack layers.
cur_lay_id = 1
prev_lay_id = 0
for i in range(num_layers-1):
  add_layer(cur_lay_id, prev_lay_id)
  cur_lay_id += 1
  prev_lay_id += 1


# Add lm final layer.
if bottleneck_dim > 0:
  network['output']['unit']['lm_bottleneck'] = {'class': 'linear', 'activation': 'relu', 'forward_weights_init': forward_weights_initializer,
                                             'n_out': bottleneck_dim, 'dropout': dropout, 'from': ['lm_dec_%s' % prev_lay_id]}
  network['output']['unit']['lm_decoder'] = {'class': 'layer_norm', 'from': ['lm_bottleneck']}
else:
  network['output']['unit']['lm_decoder'] = {'class': 'layer_norm', 'from': ['lm_dec_%s' % prev_lay_id]}

# Add lm output layer.
network['output']['unit']['lm_output'] = {
    'class': 'softmax',
    'dropout': dropout,
    'forward_weights_init': forward_weights_initializer,
    'from': ['lm_decoder'],
    "target": target,
    'with_bias': True}

# Load lm
lm_model_filename = "/work/asr3/irie/experiments/lm/librispeech/2018-03-05--lmbpe-zeyer/data-train/transfo_24_d00.2048_512.sgd.lr1.8_heads/bk-net-model/network.023"
lm_model_prefix = "lm_"

preload_from_files = {
  "lm_model" : {"filename": lm_model_filename, "prefix": lm_model_prefix},
}

# trainer
batching = "random"
log_batch_size = True
batch_size = 18000
max_seqs = 200
max_seq_length = {"classes": 75}
truncation = -1

num_epochs = 200
model = "net-model/network"
cleanup_old_models = True
gradient_clip = 0
adam = True
optimizer_epsilon = 1e-8
stop_on_nonfinite_train_score = True
tf_log_memory_usage = True
debug_grad_summaries = True
gradient_noise = 0.0
learning_rate = 0.0008
learning_rate_control = "newbob_multi_epoch"
learning_rate_control_relative_error_relative_lr = True
learning_rate_control_min_num_epochs_per_new_lr = 3
use_learning_rate_control_always = True
newbob_multi_num_epochs = EpochSplit
newbob_multi_update_interval = 1
newbob_learning_rate_decay = 0.9
learning_rate_file = "newbob.data"

# log
log = "log/crnn.%s.log" % task
log_verbosity = 5

