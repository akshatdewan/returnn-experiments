A pretrained encoder decoder model can be downloaded [here](http://www-i6.informatik.rwth-aachen.de/~zeyer/models/librispeech/enc-dec/2018.zeyer.exp3.ctc/).
A pretrained language model can be downloaded [here](http://www-i6.informatik.rwth-aachen.de/~zeyer/models/librispeech/lm/bpe-10k/2018.irie.i512_m2048_m2048.sgd_b64_lr0_cl2.newbobabs.d0.2/).

For a full training pipeline, please see [here](https://github.com/rwth-i6/returnn-experiments/tree/master/2018-asr-attention/librispeech/full-setup-attention).
